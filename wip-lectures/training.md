---
layout: page
grand_parent: WIP Lectures
parent: WIP Building
title: WIP Training
nav_order: 3.3
usemathjax: true
---

BERT
GPT-2
T5

ELECTRA

## Further reading

- [Fixing Weight Decay Regularization in Adam](https://arxiv.org/pdf/1711.05101.pdf). *I. Loshchilov, F. Hutter*. 2017.
  Introduces **AdamW**.
- [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/pdf/2003.10555.pdf). *Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning*. ICLR 2020.
- [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/pdf/2006.03654.pdf). *Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen*. ICLR 2020.
